* Statistics

** Principal Component Regression

   Let $\mathbf{T} = \mathbf{X} \mathbf{W}$ for principal component
   score matrix $\mathbf{T}$ and loading matrix $\mathbf{W}$. Set the
   models $Y = \mathbf{X} \mathbf{\beta} + \mathbf{\varepsilon}$ and
   $Y = \mathbf{T} \mathbf{\beta}_T + \mathbf{\varepsilon}$. Then,
   $\mathbf{X} \mathbf{\beta} = \mathbf{T} \mathbf{\beta}_T \iff
   \mathbf{\beta} = \mathbf{W} \mathbf{\beta}_T$.

** How to revert SVD?

   - [[https://stats.stackexchange.com/a/229093/31243][How to reverse PCA and reconstruct original variables from
     several principal components?]]
   - [[https://stats.stackexchange.com/a/134283/31243][Relationship between SVD and PCA. How to use SVD to perform PCA?]]

** How to find which variables are collinear?

   Look at the tail of the QR decomposition pivot vector (rickyrick at
   libera.chat)

   - Source: [[https://stats.stackexchange.com/a/476216/31243][How to identify which variables are collinear in a singul...]]

** Priors

   - [[http://www.stats.org.uk/priors/noninformative/YangBerger1998.pdf][A Catalog of Noninformative Priors]]

** MCMC

   - [[http://users.stat.umn.edu/~geyer/mcmc/one.html][One long run in MCMC]]: If you can't get a good answer with one
     long run, then you can't get a good answer with many short runs
     either.
